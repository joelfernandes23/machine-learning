{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "from PIL import Image\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \".\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the npy file\n",
    "orientations_test = np.load(PATH + \"/orientations_test.npy\", allow_pickle=True)\n",
    "orientations_train = np.load(PATH + \"/orientations_train.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orientations_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = os.listdir(PATH + \"/3dshapes_train/\")\n",
    "test_files = os.listdir(PATH+ \"/3dshapes_test/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "for image in train_files:\n",
    "    img = Image.open(PATH + \"/3dshapes_train/\"+ image).convert('L') # convert to grayscale \n",
    "    img = np.array(img).flatten() # flatten the image to a 1D array in order to be able to use it in the linear regression\n",
    "    train_images.append(img)\n",
    "train_data = np.array(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4096)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape # must print (10000, 4096) 10000 images with 4096 pixels each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for image in test_files:\n",
    "    img = Image.open(PATH + \"/3dshapes_test/\" +image).convert('L') # convert to grayscale \n",
    "    img = np.array(img).flatten() # flatten the image to a 1D array in order to be able to use it in the linear regression\n",
    "    test_images.append(img)\n",
    "test_data = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot single image arrays\n",
    "def plot_single_image(image):\n",
    "    # Reshape the flattened image to a 2D array\n",
    "    single_image = np.reshape(image, (64, 64))\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(single_image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_single_image(train_data[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement linear regression from scratch\n",
    "def linear_regression(X, y, learning_rate, epochs, experiment = False):\n",
    "    #keep track of time \n",
    "    start = time.time()\n",
    "    #initialize weights and bias\n",
    "    w = np.zeros(X.shape[1])\n",
    "    b = 0\n",
    "    n = len(X)\n",
    "    for i in range(epochs):\n",
    "        y_predicted = np.dot(X, w) + b\n",
    "        #calculate cost\n",
    "        cost = (1/n) * sum([val**2 for val in (y-y_predicted)])\n",
    "        #calculate gradients\n",
    "        dw = -(2/n) * np.dot(X.T, (y-y_predicted))\n",
    "        db = -(2/n) * sum(y-y_predicted)\n",
    "        #update weights and bias\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        if not experiment:\n",
    "            print(\"epoch: \", i, \",cost: \", cost)\n",
    "        if cost > 1e6:\n",
    "            print(\"cost is too high, exiting training\")\n",
    "            break\n",
    "    end = time.time()\n",
    "    print(\"training time: \", end-start)\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 ,cost:  346.2722448979581\n",
      "epoch:  1 ,cost:  647499.1321459223\n",
      "epoch:  2 ,cost:  216356884106346.78\n",
      "cost is too high, exiting training\n",
      "training time:  0.6939699649810791\n"
     ]
    }
   ],
   "source": [
    "w, b = linear_regression(train_data, orientations_train, 0.0001, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the model did not converge with the raw data. Let's try standardizing and normalizing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    # Standardize the data by subtracting the mean and dividing by the standard deviation\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    if np.count_nonzero(std==0) !=0: #check if there is any zero std to avoid divison by zero\n",
    "        std[std==0] = 1e-8\n",
    "    return (data - mean) / std\n",
    "def normalize(data):\n",
    "    # Normalize the data by subtracting the min and dividing by the max-min\n",
    "    max = np.max(data)\n",
    "    min = np.min(data)\n",
    "    if np.count_nonzero(max-min==0) !=0: #check if there is any zero std to avoid divison by zero\n",
    "        max-min == 1e-8\n",
    "    return (data - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_standardized = standardize(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "orientations_train_standardized = standardize(orientations_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 ,cost:  0.9999999999999392\n",
      "epoch:  1 ,cost:  0.9999832872259077\n",
      "epoch:  2 ,cost:  0.9999676237451266\n",
      "epoch:  3 ,cost:  0.9999527370991761\n",
      "epoch:  4 ,cost:  0.9999384550722733\n",
      "epoch:  5 ,cost:  0.9999246568654484\n",
      "epoch:  6 ,cost:  0.9999112528551761\n",
      "epoch:  7 ,cost:  0.9998981746941081\n",
      "epoch:  8 ,cost:  0.9998853695538638\n",
      "epoch:  9 ,cost:  0.9998727963035936\n",
      "epoch:  10 ,cost:  0.9998604227670375\n",
      "epoch:  11 ,cost:  0.999848223673793\n",
      "epoch:  12 ,cost:  0.9998361790999589\n",
      "epoch:  13 ,cost:  0.9998242732707943\n",
      "epoch:  14 ,cost:  0.9998124936369673\n",
      "epoch:  15 ,cost:  0.9998008301603092\n",
      "epoch:  16 ,cost:  0.9997892747605406\n",
      "epoch:  17 ,cost:  0.999777820886092\n",
      "epoch:  18 ,cost:  0.9997664631809156\n",
      "epoch:  19 ,cost:  0.9997551972254964\n",
      "epoch:  20 ,cost:  0.9997440193353694\n",
      "epoch:  21 ,cost:  0.9997329264041616\n",
      "epoch:  22 ,cost:  0.9997219157813545\n",
      "epoch:  23 ,cost:  0.9997109851767658\n",
      "epoch:  24 ,cost:  0.9997001325861077\n",
      "epoch:  25 ,cost:  0.9996893562326449\n",
      "epoch:  26 ,cost:  0.9996786545216577\n",
      "epoch:  27 ,cost:  0.9996680260046773\n",
      "epoch:  28 ,cost:  0.9996574693514846\n",
      "epoch:  29 ,cost:  0.9996469833280796\n",
      "epoch:  30 ,cost:  0.9996365667793519\n",
      "epoch:  31 ,cost:  0.9996262186154594\n",
      "epoch:  32 ,cost:  0.999615937801042\n",
      "epoch:  33 ,cost:  0.9996057233466765\n",
      "epoch:  34 ,cost:  0.9995955743021175\n",
      "epoch:  35 ,cost:  0.9995854897509322\n",
      "epoch:  36 ,cost:  0.9995754688061583\n",
      "epoch:  37 ,cost:  0.9995655106069015\n",
      "epoch:  38 ,cost:  0.9995556143155274\n",
      "epoch:  39 ,cost:  0.9995457791154324\n",
      "epoch:  40 ,cost:  0.9995360042091903\n",
      "epoch:  41 ,cost:  0.9995262888170765\n",
      "epoch:  42 ,cost:  0.9995166321758024\n",
      "epoch:  43 ,cost:  0.9995070335374973\n",
      "epoch:  44 ,cost:  0.9994974921688647\n",
      "epoch:  45 ,cost:  0.9994880073503635\n",
      "epoch:  46 ,cost:  0.9994785783756727\n",
      "epoch:  47 ,cost:  0.9994692045510698\n",
      "epoch:  48 ,cost:  0.9994598851949861\n",
      "epoch:  49 ,cost:  0.9994506196375962\n",
      "epoch:  50 ,cost:  0.9994414072203814\n",
      "epoch:  51 ,cost:  0.9994322472958499\n",
      "epoch:  52 ,cost:  0.999423139227182\n",
      "epoch:  53 ,cost:  0.9994140823879464\n",
      "epoch:  54 ,cost:  0.9994050761618722\n",
      "epoch:  55 ,cost:  0.9993961199425528\n",
      "epoch:  56 ,cost:  0.9993872131332301\n",
      "epoch:  57 ,cost:  0.9993783551465766\n",
      "epoch:  58 ,cost:  0.9993695454044997\n",
      "epoch:  59 ,cost:  0.999360783337901\n",
      "epoch:  60 ,cost:  0.9993520683865451\n",
      "epoch:  61 ,cost:  0.9993433999988156\n",
      "epoch:  62 ,cost:  0.9993347776315817\n",
      "epoch:  63 ,cost:  0.9993262007500225\n",
      "epoch:  64 ,cost:  0.9993176688274388\n",
      "epoch:  65 ,cost:  0.9993091813451367\n",
      "epoch:  66 ,cost:  0.999300737792242\n",
      "epoch:  67 ,cost:  0.9992923376655393\n",
      "epoch:  68 ,cost:  0.9992839804693713\n",
      "epoch:  69 ,cost:  0.9992756657154754\n",
      "epoch:  70 ,cost:  0.9992673929228448\n",
      "epoch:  71 ,cost:  0.9992591616176031\n",
      "epoch:  72 ,cost:  0.9992509713328418\n",
      "epoch:  73 ,cost:  0.9992428216085717\n",
      "epoch:  74 ,cost:  0.9992347119914959\n",
      "epoch:  75 ,cost:  0.9992266420349923\n",
      "epoch:  76 ,cost:  0.9992186112989075\n",
      "epoch:  77 ,cost:  0.9992106193495124\n",
      "epoch:  78 ,cost:  0.9992026657593431\n",
      "epoch:  79 ,cost:  0.9991947501071063\n",
      "epoch:  80 ,cost:  0.9991868719775905\n",
      "epoch:  81 ,cost:  0.9991790309615339\n",
      "epoch:  82 ,cost:  0.9991712266555224\n",
      "epoch:  83 ,cost:  0.9991634586619134\n",
      "epoch:  84 ,cost:  0.9991557265887305\n",
      "epoch:  85 ,cost:  0.9991480300495367\n",
      "epoch:  86 ,cost:  0.9991403686633863\n",
      "epoch:  87 ,cost:  0.9991327420546926\n",
      "epoch:  88 ,cost:  0.9991251498531744\n",
      "epoch:  89 ,cost:  0.9991175916937289\n",
      "epoch:  90 ,cost:  0.9991100672163812\n",
      "epoch:  91 ,cost:  0.9991025760661757\n",
      "epoch:  92 ,cost:  0.9990951178930962\n",
      "epoch:  93 ,cost:  0.9990876923519904\n",
      "epoch:  94 ,cost:  0.9990802991025023\n",
      "epoch:  95 ,cost:  0.999072937808958\n",
      "epoch:  96 ,cost:  0.9990656081403175\n",
      "epoch:  97 ,cost:  0.9990583097700828\n",
      "epoch:  98 ,cost:  0.9990510423762547\n",
      "epoch:  99 ,cost:  0.9990438056412232\n",
      "training time:  2.1202611923217773\n"
     ]
    }
   ],
   "source": [
    "w_s, b_s = linear_regression(train_data_standardized, orientations_train_standardized, 0.0001, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model did converge with the standardized data but also let's try to normalize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_normalized = normalize(train_data)\n",
    "orientations_train_normalized = normalize(orientations_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 ,cost:  0.34704387755102584\n",
      "epoch:  1 ,cost:  0.21847079866655686\n",
      "epoch:  2 ,cost:  0.15673147926989806\n",
      "epoch:  3 ,cost:  0.12707600025298468\n",
      "epoch:  4 ,cost:  0.11282260010007776\n",
      "epoch:  5 ,cost:  0.10596316809502841\n",
      "epoch:  6 ,cost:  0.10265339483816859\n",
      "epoch:  7 ,cost:  0.10104781108229209\n",
      "epoch:  8 ,cost:  0.10026049432393223\n",
      "epoch:  9 ,cost:  0.09986615417728066\n",
      "epoch:  10 ,cost:  0.0996606275316207\n",
      "epoch:  11 ,cost:  0.09954590383089426\n",
      "epoch:  12 ,cost:  0.09947493125706236\n",
      "epoch:  13 ,cost:  0.09942512084132421\n",
      "epoch:  14 ,cost:  0.09938562706598646\n",
      "epoch:  15 ,cost:  0.09935124189487754\n",
      "epoch:  16 ,cost:  0.09931946359174308\n",
      "epoch:  17 ,cost:  0.09928908960118868\n",
      "epoch:  18 ,cost:  0.09925954105852902\n",
      "epoch:  19 ,cost:  0.09923053851937602\n",
      "epoch:  20 ,cost:  0.09920194629288828\n",
      "epoch:  21 ,cost:  0.09917369771350064\n",
      "epoch:  22 ,cost:  0.09914575926731493\n",
      "epoch:  23 ,cost:  0.09911811337074333\n",
      "epoch:  24 ,cost:  0.09909075010320072\n",
      "epoch:  25 ,cost:  0.09906366323820044\n",
      "epoch:  26 ,cost:  0.0990368483379176\n",
      "epoch:  27 ,cost:  0.09901030183831387\n",
      "epoch:  28 ,cost:  0.09898402060979239\n",
      "epoch:  29 ,cost:  0.09895800174613267\n",
      "epoch:  30 ,cost:  0.09893224246301092\n",
      "epoch:  31 ,cost:  0.09890674004912892\n",
      "epoch:  32 ,cost:  0.09888149184260159\n",
      "epoch:  33 ,cost:  0.09885649521947334\n",
      "epoch:  34 ,cost:  0.09883174758804701\n",
      "epoch:  35 ,cost:  0.09880724638602388\n",
      "epoch:  36 ,cost:  0.09878298907897627\n",
      "epoch:  37 ,cost:  0.09875897315947264\n",
      "epoch:  38 ,cost:  0.09873519614651424\n",
      "epoch:  39 ,cost:  0.09871165558512267\n",
      "epoch:  40 ,cost:  0.09868834904599813\n",
      "epoch:  41 ,cost:  0.09866527412522096\n",
      "epoch:  42 ,cost:  0.09864242844396903\n",
      "epoch:  43 ,cost:  0.09861980964824486\n",
      "epoch:  44 ,cost:  0.09859741540861232\n",
      "epoch:  45 ,cost:  0.09857524341993582\n",
      "epoch:  46 ,cost:  0.0985532914011227\n",
      "epoch:  47 ,cost:  0.0985315570948703\n",
      "epoch:  48 ,cost:  0.09851003826741442\n",
      "epoch:  49 ,cost:  0.09848873270828397\n",
      "epoch:  50 ,cost:  0.09846763823005311\n",
      "epoch:  51 ,cost:  0.09844675266809808\n",
      "epoch:  52 ,cost:  0.09842607388036127\n",
      "epoch:  53 ,cost:  0.0984055997471087\n",
      "epoch:  54 ,cost:  0.09838532817069794\n",
      "epoch:  55 ,cost:  0.09836525707534452\n",
      "epoch:  56 ,cost:  0.0983453844068944\n",
      "epoch:  57 ,cost:  0.09832570813259152\n",
      "epoch:  58 ,cost:  0.09830622624085629\n",
      "epoch:  59 ,cost:  0.09828693674106379\n",
      "epoch:  60 ,cost:  0.09826783766331905\n",
      "epoch:  61 ,cost:  0.09824892705824341\n",
      "epoch:  62 ,cost:  0.09823020299675504\n",
      "epoch:  63 ,cost:  0.09821166356985903\n",
      "epoch:  64 ,cost:  0.09819330688843325\n",
      "epoch:  65 ,cost:  0.0981751310830211\n",
      "epoch:  66 ,cost:  0.09815713430362343\n",
      "epoch:  67 ,cost:  0.0981393147194947\n",
      "epoch:  68 ,cost:  0.098121670518941\n",
      "epoch:  69 ,cost:  0.0981041999091195\n",
      "epoch:  70 ,cost:  0.09808690111584073\n",
      "epoch:  71 ,cost:  0.0980697723833699\n",
      "epoch:  72 ,cost:  0.09805281197423608\n",
      "epoch:  73 ,cost:  0.09803601816903955\n",
      "epoch:  74 ,cost:  0.09801938926626189\n",
      "epoch:  75 ,cost:  0.09800292358207624\n",
      "epoch:  76 ,cost:  0.09798661945016483\n",
      "epoch:  77 ,cost:  0.09797047522153231\n",
      "epoch:  78 ,cost:  0.09795448926432349\n",
      "epoch:  79 ,cost:  0.09793865996364652\n",
      "epoch:  80 ,cost:  0.09792298572139181\n",
      "epoch:  81 ,cost:  0.09790746495605694\n",
      "epoch:  82 ,cost:  0.09789209610257094\n",
      "epoch:  83 ,cost:  0.09787687761212494\n",
      "epoch:  84 ,cost:  0.09786180795199734\n",
      "epoch:  85 ,cost:  0.09784688560538764\n",
      "epoch:  86 ,cost:  0.09783210907124879\n",
      "epoch:  87 ,cost:  0.09781747686412187\n",
      "epoch:  88 ,cost:  0.09780298751397233\n",
      "epoch:  89 ,cost:  0.09778863956602628\n",
      "epoch:  90 ,cost:  0.09777443158061495\n",
      "epoch:  91 ,cost:  0.09776036213300998\n",
      "epoch:  92 ,cost:  0.09774642981327358\n",
      "epoch:  93 ,cost:  0.09773263322609699\n",
      "epoch:  94 ,cost:  0.09771897099065247\n",
      "epoch:  95 ,cost:  0.09770544174043518\n",
      "epoch:  96 ,cost:  0.09769204412312082\n",
      "epoch:  97 ,cost:  0.09767877680040822\n",
      "epoch:  98 ,cost:  0.09766563844788043\n",
      "epoch:  99 ,cost:  0.0976526277548529\n",
      "training time:  2.139819860458374\n"
     ]
    }
   ],
   "source": [
    "w_n, b_n = linear_regression(train_data_normalized, orientations_train_normalized, 0.0001, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both normalizing and standardizing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ns = standardize(train_data_normalized)\n",
    "orientations_train_ns = standardize(orientations_train_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 ,cost:  346.2722448979581\n",
      "epoch:  1 ,cost:  346.26475268002054\n",
      "epoch:  2 ,cost:  346.25897895042937\n",
      "epoch:  3 ,cost:  346.25386879668775\n",
      "epoch:  4 ,cost:  346.2490591764227\n",
      "epoch:  5 ,cost:  346.2444173922829\n",
      "epoch:  6 ,cost:  346.2398892155386\n",
      "epoch:  7 ,cost:  346.235448488707\n",
      "epoch:  8 ,cost:  346.23108008499435\n",
      "epoch:  9 ,cost:  346.22677390783815\n",
      "epoch:  10 ,cost:  346.2225226014351\n",
      "epoch:  11 ,cost:  346.21832055156426\n",
      "epoch:  12 ,cost:  346.2141633668185\n",
      "epoch:  13 ,cost:  346.2100475615553\n",
      "epoch:  14 ,cost:  346.20597033886486\n",
      "epoch:  15 ,cost:  346.2019294323327\n",
      "epoch:  16 ,cost:  346.1979229869934\n",
      "epoch:  17 ,cost:  346.19394946839543\n",
      "epoch:  18 ,cost:  346.19000759266237\n",
      "epoch:  19 ,cost:  346.1860962724708\n",
      "epoch:  20 ,cost:  346.1822145752067\n",
      "epoch:  21 ,cost:  346.1783616905029\n",
      "epoch:  22 ,cost:  346.17453690499696\n",
      "epoch:  23 ,cost:  346.17073958266906\n",
      "epoch:  24 ,cost:  346.1669691495285\n",
      "epoch:  25 ,cost:  346.1632250816064\n",
      "epoch:  26 ,cost:  346.15950689559804\n",
      "epoch:  27 ,cost:  346.1558141414673\n",
      "epoch:  28 ,cost:  346.15214639667704\n",
      "epoch:  29 ,cost:  346.1485032616057\n",
      "epoch:  30 ,cost:  346.1448843559297\n",
      "epoch:  31 ,cost:  346.14128931577005\n",
      "epoch:  32 ,cost:  346.13771779138636\n",
      "epoch:  33 ,cost:  346.13416944535817\n",
      "epoch:  34 ,cost:  346.13064395111786\n",
      "epoch:  35 ,cost:  346.1271409917576\n",
      "epoch:  36 ,cost:  346.12366025907136\n",
      "epoch:  37 ,cost:  346.1202014527584\n",
      "epoch:  38 ,cost:  346.1167642797771\n",
      "epoch:  39 ,cost:  346.1133484538072\n",
      "epoch:  40 ,cost:  346.10995369479457\n",
      "epoch:  41 ,cost:  346.10657972857814\n",
      "epoch:  42 ,cost:  346.1032262865474\n",
      "epoch:  43 ,cost:  346.09989310538555\n",
      "epoch:  44 ,cost:  346.0965799268062\n",
      "epoch:  45 ,cost:  346.09328649735505\n",
      "epoch:  46 ,cost:  346.09001256821244\n",
      "epoch:  47 ,cost:  346.08675789501984\n",
      "epoch:  48 ,cost:  346.0835222377461\n",
      "epoch:  49 ,cost:  346.0803053605306\n",
      "epoch:  50 ,cost:  346.07710703156147\n",
      "epoch:  51 ,cost:  346.0739270229637\n",
      "epoch:  52 ,cost:  346.07076511068436\n",
      "epoch:  53 ,cost:  346.0676210743916\n",
      "epoch:  54 ,cost:  346.0644946973896\n",
      "epoch:  55 ,cost:  346.06138576650903\n",
      "epoch:  56 ,cost:  346.0582940720399\n",
      "epoch:  57 ,cost:  346.0552194076412\n",
      "epoch:  58 ,cost:  346.0521615702677\n",
      "epoch:  59 ,cost:  346.04912036009694\n",
      "epoch:  60 ,cost:  346.04609558045416\n",
      "epoch:  61 ,cost:  346.043087037749\n",
      "epoch:  62 ,cost:  346.0400945414118\n",
      "epoch:  63 ,cost:  346.0371179038228\n",
      "epoch:  64 ,cost:  346.03415694025716\n",
      "epoch:  65 ,cost:  346.03121146883484\n",
      "epoch:  66 ,cost:  346.0282813104463\n",
      "epoch:  67 ,cost:  346.0253662887093\n",
      "epoch:  68 ,cost:  346.022466229917\n",
      "epoch:  69 ,cost:  346.01958096298\n",
      "epoch:  70 ,cost:  346.0167103193742\n",
      "epoch:  71 ,cost:  346.01385413310993\n",
      "epoch:  72 ,cost:  346.01101224066576\n",
      "epoch:  73 ,cost:  346.0081844809408\n",
      "epoch:  74 ,cost:  346.0053706952284\n",
      "epoch:  75 ,cost:  346.00257072716016\n",
      "epoch:  76 ,cost:  345.9997844226649\n",
      "epoch:  77 ,cost:  345.9970116299238\n",
      "epoch:  78 ,cost:  345.9942521993369\n",
      "epoch:  79 ,cost:  345.99150598347825\n",
      "epoch:  80 ,cost:  345.9887728370674\n",
      "epoch:  81 ,cost:  345.98605261691387\n",
      "epoch:  82 ,cost:  345.9833451818961\n",
      "epoch:  83 ,cost:  345.98065039291885\n",
      "epoch:  84 ,cost:  345.97796811287844\n",
      "epoch:  85 ,cost:  345.9752982066293\n",
      "epoch:  86 ,cost:  345.9726405409504\n",
      "epoch:  87 ,cost:  345.96999498451146\n",
      "epoch:  88 ,cost:  345.9673614078424\n",
      "epoch:  89 ,cost:  345.96473968329764\n",
      "epoch:  90 ,cost:  345.96212968503596\n",
      "epoch:  91 ,cost:  345.95953128897384\n",
      "epoch:  92 ,cost:  345.956944372773\n",
      "epoch:  93 ,cost:  345.95436881578985\n",
      "epoch:  94 ,cost:  345.9518044990808\n",
      "epoch:  95 ,cost:  345.94925130533505\n",
      "epoch:  96 ,cost:  345.9467091188796\n",
      "epoch:  97 ,cost:  345.9441778256306\n",
      "epoch:  98 ,cost:  345.9416573130802\n",
      "epoch:  99 ,cost:  345.9391474702644\n",
      "training time:  2.059866189956665\n"
     ]
    }
   ],
   "source": [
    "w_ns, b_ns = linear_regression(train_data_ns, orientations_train, 0.0001, 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the test data the same way we processed the train data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_standardized = standardize(test_data)\n",
    "test_data_normalized = normalize(test_data)\n",
    "test_data_ns = standardize(test_data_normalized)\n",
    "orientations_test_standardized = standardize(orientations_test)\n",
    "orientations_test_normalized = normalize(orientations_test)\n",
    "orientations_test_ns = standardize(orientations_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, w, b):\n",
    "    #keep track of prediction time\n",
    "    start = time.time()\n",
    "    y_predicted = np.dot(X, w) + b\n",
    "    end = time.time()\n",
    "    print(\"prediction time: \", end-start)\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, y, w, b):\n",
    "    y_predicted = predict(X, w, b)\n",
    "    #print the root mean squared error\n",
    "    rmse = np.sqrt(np.mean((y-y_predicted)**2))\n",
    "    print(\"RMSE: \", rmse)\n",
    "    return rmse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model on raw, standardized, normalized and standardized normalized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction time:  0.003904104232788086\n",
      "RMSE:  269556034423.19086\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "269556034423.19086"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_data, orientations_test, w, b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE for the standardized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction time:  0.0019450187683105469\n",
      "RMSE:  0.9997034124907559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9997034124907559"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_data_standardized, orientations_test_standardized, w_s, b_s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE for the normalized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction time:  0.0016269683837890625\n",
      "RMSE:  0.30825764366138175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.30825764366138175"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_data_normalized, orientations_test_normalized, w_n, b_n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE for the normalized and standardized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction time:  0.0012400150299072266\n",
      "RMSE:  1.0174976942371743\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0174976942371743"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(test_data_ns, orientations_test_ns, w_ns, b_ns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems like normalizing the data gives the best result. \\\n",
    "Let's try different learning rates to see if it improves the performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [1e-10, 1e-9, 1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 1000, 10000]\n",
    "epoch = 100\n",
    "def run_experiment(lr_list, epoch):\n",
    "    rmse_list = []\n",
    "    for lr in lr_list:\n",
    "        w, b = linear_regression(train_data_normalized, orientations_train_normalized, lr, epoch, experiment= True)\n",
    "        print(\"lr: \", lr)\n",
    "        rmse = test(test_data_normalized, orientations_test_normalized, w, b)\n",
    "        rmse_list.append(rmse)\n",
    "        if rmse == min(rmse_list):\n",
    "            lr_best = lr\n",
    "    print(\"-\"*50)\n",
    "    print(\"best lr: \", lr_best, \"best rmse: \", min(rmse_list))    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  2.0476930141448975\n",
      "lr:  1e-10\n",
      "prediction time:  0.0008189678192138672\n",
      "RMSE:  0.5977890097697146\n",
      "training time:  1.9889090061187744\n",
      "lr:  1e-09\n",
      "prediction time:  0.0008089542388916016\n",
      "RMSE:  0.5976712491865219\n",
      "training time:  2.0586581230163574\n",
      "lr:  1e-08\n",
      "prediction time:  0.0009949207305908203\n",
      "RMSE:  0.5964958876439755\n",
      "training time:  2.1226401329040527\n",
      "lr:  1e-07\n",
      "prediction time:  0.0007691383361816406\n",
      "RMSE:  0.5849645335391934\n",
      "training time:  2.0342869758605957\n",
      "lr:  1e-06\n",
      "prediction time:  0.000942230224609375\n",
      "RMSE:  0.4898183291680657\n",
      "training time:  2.06659197807312\n",
      "lr:  1e-05\n",
      "prediction time:  0.0008490085601806641\n",
      "RMSE:  0.3126016558711412\n",
      "training time:  2.0331921577453613\n",
      "lr:  0.0001\n",
      "prediction time:  0.0007991790771484375\n",
      "RMSE:  0.30825764366138175\n",
      "cost is too high, exiting training\n",
      "training time:  0.24042510986328125\n",
      "lr:  0.001\n",
      "prediction time:  0.0010857582092285156\n",
      "RMSE:  3114.141879206618\n",
      "cost is too high, exiting training\n",
      "training time:  0.08038711547851562\n",
      "lr:  0.01\n",
      "prediction time:  0.000637054443359375\n",
      "RMSE:  389017.12299877155\n",
      "cost is too high, exiting training\n",
      "training time:  0.05994892120361328\n",
      "lr:  0.1\n",
      "prediction time:  0.0006480216979980469\n",
      "RMSE:  14317947.410078859\n",
      "cost is too high, exiting training\n",
      "training time:  0.03997492790222168\n",
      "lr:  1\n",
      "prediction time:  0.0006978511810302734\n",
      "RMSE:  4704431.649362564\n",
      "cost is too high, exiting training\n",
      "training time:  0.0402989387512207\n",
      "lr:  10\n",
      "prediction time:  0.0008418560028076172\n",
      "RMSE:  470718997.1910955\n",
      "cost is too high, exiting training\n",
      "training time:  0.04165196418762207\n",
      "lr:  1000\n",
      "prediction time:  0.0008020401000976562\n",
      "RMSE:  4707493437865.533\n",
      "cost is too high, exiting training\n",
      "training time:  0.03750777244567871\n",
      "lr:  10000\n",
      "prediction time:  0.0008559226989746094\n",
      "RMSE:  470749619669283.06\n",
      "--------------------------------------------------\n",
      "best lr:  0.0001 best rmse:  0.30825764366138175\n"
     ]
    }
   ],
   "source": [
    "run_experiment(lr_list, epoch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after all it seems like normalizing the data and setting the learning rate to 1e-4 gives the best RMSE result: 0.308"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_regressor(data_type, n_estimators, random_state):\n",
    "    if data_type == \"raw\":\n",
    "        train = train_data\n",
    "        train_labels = orientations_train\n",
    "        test = test_data\n",
    "        test_labels = orientations_test\n",
    "    elif data_type == \"standardized\":\n",
    "        train = train_data_standardized\n",
    "        train_labels = orientations_train_standardized\n",
    "        test = test_data_standardized\n",
    "        test_labels = orientations_test_standardized\n",
    "    elif data_type == \"normalized\":\n",
    "        train = train_data_normalized\n",
    "        train_labels = orientations_train_normalized\n",
    "        test = test_data_normalized\n",
    "        test_labels = orientations_test_normalized\n",
    "    elif data_type == \"ns\":\n",
    "        train = train_data_ns\n",
    "        train_labels = orientations_train_ns\n",
    "        test = test_data_ns\n",
    "        test_labels = orientations_test_ns\n",
    "    start = time.time()\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, random_state=random_state)\n",
    "    rf.fit(train, train_labels)\n",
    "    end = time.time()\n",
    "    print(\"time to train: \", end-start, \"s\")\n",
    "    #predict the test data\n",
    "    start = time.time()\n",
    "    y_predicted = rf.predict(test)\n",
    "    end = time.time()\n",
    "    print(\"time to predict: \", end-start, \"s\")\n",
    "    #print the root mean squared error\n",
    "    print(\"RMSE: \", np.sqrt(np.mean((test_labels-y_predicted)**2)))\n",
    "    return rf\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train:  41.764158964157104 s\n",
      "time to predict:  0.008419036865234375 s\n",
      "RMSE:  23.119035358733445\n"
     ]
    }
   ],
   "source": [
    "rf_raw = random_forest_regressor(\"raw\", 2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train:  41.61218190193176 s\n",
      "time to predict:  0.01462411880493164 s\n",
      "RMSE:  0.38176216017145487\n"
     ]
    }
   ],
   "source": [
    "rf_normalized = random_forest_regressor(\"normalized\", 2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train:  41.849705934524536 s\n",
      "time to predict:  0.013397932052612305 s\n",
      "RMSE:  1.256570455682076\n"
     ]
    }
   ],
   "source": [
    "rf_standardized = random_forest_regressor(\"standardized\", 2, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train:  41.15413999557495 s\n",
      "time to predict:  0.013397932052612305 s\n",
      "RMSE:  1.2530851102878386\n"
     ]
    }
   ],
   "source": [
    "rf_ns = random_forest_regressor(\"ns\", 2, 42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now try k-nn regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "def KNN_model(data_type, n_neighbors, leaf_size, random_state = 42):\n",
    "    if data_type == \"raw\":\n",
    "        train = train_data\n",
    "        train_labels = orientations_train\n",
    "        test = test_data\n",
    "        test_labels = orientations_test\n",
    "    elif data_type == \"standardized\":\n",
    "        train = train_data_standardized\n",
    "        train_labels = orientations_train_standardized\n",
    "        test = test_data_standardized\n",
    "        test_labels = orientations_test_standardized\n",
    "    elif data_type == \"normalized\":\n",
    "        train = train_data_normalized\n",
    "        train_labels = orientations_train_normalized\n",
    "        test = test_data_normalized\n",
    "        test_labels = orientations_test_normalized\n",
    "    elif data_type == \"ns\":\n",
    "        train = train_data_ns\n",
    "        train_labels = orientations_train_ns\n",
    "        test = test_data_ns\n",
    "        test_labels = orientations_test_ns\n",
    "    start = time.time()\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors, leaf_size=leaf_size)\n",
    "    knn.fit(train, train_labels)\n",
    "    end = time.time()\n",
    "    print(\"time to train: \", end-start, \"s\")\n",
    "    #predict the test data\n",
    "    start = time.time()\n",
    "    y_predicted = knn.predict(test)\n",
    "    end = time.time()\n",
    "    print(\"time to predict: \", end-start, \"s\")\n",
    "    #print the root mean squared error\n",
    "    print(\"RMSE: \", np.sqrt(np.mean((test_labels-y_predicted)**2)))\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train:  0.0025529861450195312 s\n",
      "time to predict:  1.3807270526885986 s\n",
      "RMSE:  21.898467004401407\n"
     ]
    }
   ],
   "source": [
    "knn_raw = KNN_model(\"raw\", 3, 10, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train:  0.1381969451904297 s\n",
      "time to predict:  1.118708848953247 s\n",
      "RMSE:  0.3647274010785393\n"
     ]
    }
   ],
   "source": [
    "knn_normalized = KNN_model(\"normalized\", 3, 10, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train:  0.1271531581878662 s\n",
      "time to predict:  1.0529909133911133 s\n",
      "RMSE:  1.1887345553719364\n"
     ]
    }
   ],
   "source": [
    "knn_standardized = KNN_model(\"standardized\", 3, 10, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time to train:  0.12516498565673828 s\n",
      "time to predict:  1.1720399856567383 s\n",
      "RMSE:  1.1887345553719362\n"
     ]
    }
   ],
   "source": [
    "knn_ns = KNN_model(\"ns\", 3, 10, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start a grid search for the best parameters\n",
    "def grid_search_KNN(data_type, train, test, train_labels, test_labels):\n",
    "    if data_type == \"raw\":\n",
    "        train = train_data\n",
    "        train_labels = orientations_train\n",
    "        test = test_data\n",
    "        test_labels = orientations_test\n",
    "    elif data_type == \"standardized\":\n",
    "        train = train_data_standardized\n",
    "        train_labels = orientations_train_standardized\n",
    "        test = test_data_standardized\n",
    "        test_labels = orientations_test_standardized\n",
    "    elif data_type == \"normalized\":\n",
    "        train = train_data_normalized\n",
    "        train_labels = orientations_train_normalized\n",
    "        test = test_data_normalized\n",
    "        test_labels = orientations_test_normalized\n",
    "    elif data_type == \"ns\":\n",
    "        train = train_data_ns\n",
    "        train_labels = orientations_train_ns\n",
    "        test = test_data_ns\n",
    "        test_labels = orientations_test_ns\n",
    "\n",
    "    n_neighbors = [1, 2, 3, 4]\n",
    "    leaf_size = [10, 20]\n",
    "    rmse_list = []\n",
    "    for n in n_neighbors:\n",
    "        for l in leaf_size:\n",
    "            knn = KNeighborsRegressor(n_neighbors=n, leaf_size=l)\n",
    "            knn.fit(train, train_labels)\n",
    "            y_predicted = knn.predict(test)\n",
    "            rmse = np.sqrt(np.mean((test_labels-y_predicted)**2))\n",
    "            print(\"n_neighbors: \", n, \"leaf_size: \", l, \"RMSE: \", rmse)\n",
    "            rmse_list.append(rmse)\n",
    "    print(\"-\"*50)\n",
    "    print(\"best rmse: \", min(rmse_list))\n",
    "    print(\"n_neighbors: \", n_neighbors[rmse_list.index(min(rmse_list))//80])\n",
    "    print(\"leaf_size: \", leaf_size[rmse_list.index(min(rmse_list))//10%8])\n",
    "    return rmse_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors:  1 leaf_size:  10 RMSE:  26.636326277304466\n",
      "n_neighbors:  1 leaf_size:  20 RMSE:  26.636326277304466\n",
      "n_neighbors:  2 leaf_size:  10 RMSE:  23.21615377099246\n",
      "n_neighbors:  2 leaf_size:  20 RMSE:  23.21615377099246\n",
      "n_neighbors:  3 leaf_size:  10 RMSE:  21.898467004401407\n",
      "n_neighbors:  3 leaf_size:  20 RMSE:  21.898467004401407\n",
      "n_neighbors:  4 leaf_size:  10 RMSE:  21.008498644741906\n",
      "n_neighbors:  4 leaf_size:  20 RMSE:  21.008498644741906\n",
      "--------------------------------------------------\n",
      "best rmse:  21.008498644741906\n",
      "n_neighbors:  1\n",
      "leaf_size:  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[26.636326277304466,\n",
       " 26.636326277304466,\n",
       " 23.21615377099246,\n",
       " 23.21615377099246,\n",
       " 21.898467004401407,\n",
       " 21.898467004401407,\n",
       " 21.008498644741906,\n",
       " 21.008498644741906]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_KNN(\"raw\", train_data, test_data, orientations_train, orientations_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors:  1 leaf_size:  10 RMSE:  0.44219420426517836\n",
      "n_neighbors:  1 leaf_size:  20 RMSE:  0.44219420426517836\n",
      "n_neighbors:  2 leaf_size:  10 RMSE:  0.3876193035567191\n",
      "n_neighbors:  2 leaf_size:  20 RMSE:  0.3876193035567191\n",
      "n_neighbors:  3 leaf_size:  10 RMSE:  0.3647274010785393\n",
      "n_neighbors:  3 leaf_size:  20 RMSE:  0.3647274010785393\n",
      "n_neighbors:  4 leaf_size:  10 RMSE:  0.3507158313902512\n",
      "n_neighbors:  4 leaf_size:  20 RMSE:  0.3507158313902512\n",
      "--------------------------------------------------\n",
      "best rmse:  0.3507158313902512\n",
      "n_neighbors:  1\n",
      "leaf_size:  10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.44219420426517836,\n",
       " 0.44219420426517836,\n",
       " 0.3876193035567191,\n",
       " 0.3876193035567191,\n",
       " 0.3647274010785393,\n",
       " 0.3647274010785393,\n",
       " 0.3507158313902512,\n",
       " 0.3507158313902512]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_KNN(\"normalized\", train_data_normalized, test_data_normalized, orientations_train_normalized, orientations_test_normalized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "256c06ca0f29c2c6134eaf1d25b5b5fe33f36dfda22caac05cf4ab778f794e01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
